{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"Copy of hw1p2_testing.ipynb","provenance":[{"file_id":"1EwBnDmH_l5HxoZP0xOWNXHuHIX6ph8Ds","timestamp":1569423146677}],"collapsed_sections":["dGL7EPvRBQst","nFNFqW3NBQsu","7zsvA-OrBQsu","x71SZjggBQs6","GfmZ5jn6BQs_","5NQB7-hBBQtK","-HysMAnmBQtP","Dnq4DoDtBQtQ","WCEaDfP_BQtS","XJ8fpqNBBQtY"]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"9FPTpQUvBQrj","colab_type":"text"},"source":["# Neural Network Optimization and Tuning\n","\n","You've learned how to build computational graphs in PyTorch and compute gradients. The final piece to training a network is applying the gradients to update the network parameters. In this tutorial you will learn how to implement a number of optimization techniques in PyTorch along with other tuning methods. "]},{"cell_type":"code","metadata":{"id":"IiW3SBB-NKGr","colab_type":"code","colab":{}},"source":["import torch\n","import random\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import transforms, datasets, models\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.autograd import Variable\n","from collections import namedtuple\n","from IPython.display import Image\n","import multiprocessing\n","import pdb \n","%matplotlib inline\n","np.random.seed(2019)\n","\n","np_load_old = np.load\n","\n","#modify the default parameters of np.load\n","np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LB9Q-Zv4aO5q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"33da83e3-93a2-40ba-ec39-2355053f84d0","executionInfo":{"status":"error","timestamp":1569381409440,"user_tz":240,"elapsed":483,"user":{"displayName":"Alexander Shypula","photoUrl":"","userId":"04633353775377489102"}}},"source":["np.reload(load)"],"execution_count":94,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-94-ca415f4a9811>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'reload'"]}]},{"cell_type":"code","metadata":{"id":"60kqp7KibC9e","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"3d31d5f4-e1a0-4d08-cac3-c702dbc00652","executionInfo":{"status":"ok","timestamp":1569381437411,"user_tz":240,"elapsed":468,"user":{"displayName":"Alexander Shypula","photoUrl":"","userId":"04633353775377489102"}}},"source":["import importlib\n","importlib.reload(np)"],"execution_count":95,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<module 'numpy' from '/usr/local/lib/python3.6/dist-packages/numpy/__init__.py'>"]},"metadata":{"tags":[]},"execution_count":95}]},{"cell_type":"code","metadata":{"id":"plrUm2bFaGUU","colab_type":"code","colab":{}},"source":["\n","def load(file, mmap_mode=None, allow_pickle=True, fix_imports=True,\n","         encoding='ASCII'):\n","    \"\"\"\n","    Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files.\n","    Parameters\n","    ----------\n","    file : file-like object, string, or pathlib.Path\n","        The file to read. File-like objects must support the\n","        ``seek()`` and ``read()`` methods. Pickled files require that the\n","        file-like object support the ``readline()`` method as well.\n","    mmap_mode : {None, 'r+', 'r', 'w+', 'c'}, optional\n","        If not None, then memory-map the file, using the given mode (see\n","        `numpy.memmap` for a detailed description of the modes).  A\n","        memory-mapped array is kept on disk. However, it can be accessed\n","        and sliced like any ndarray.  Memory mapping is especially useful\n","        for accessing small fragments of large files without reading the\n","        entire file into memory.\n","    allow_pickle : bool, optional\n","        Allow loading pickled object arrays stored in npy files. Reasons for\n","        disallowing pickles include security, as loading pickled data can\n","        execute arbitrary code. If pickles are disallowed, loading object\n","        arrays will fail.\n","        Default: True\n","    fix_imports : bool, optional\n","        Only useful when loading Python 2 generated pickled files on Python 3,\n","        which includes npy/npz files containing object arrays. If `fix_imports`\n","        is True, pickle will try to map the old Python 2 names to the new names\n","        used in Python 3.\n","    encoding : str, optional\n","        What encoding to use when reading Python 2 strings. Only useful when\n","        loading Python 2 generated pickled files in Python 3, which includes\n","        npy/npz files containing object arrays. Values other than 'latin1',\n","        'ASCII', and 'bytes' are not allowed, as they can corrupt numerical\n","        data. Default: 'ASCII'\n","    Returns\n","    -------\n","    result : array, tuple, dict, etc.\n","        Data stored in the file. For ``.npz`` files, the returned instance\n","        of NpzFile class must be closed to avoid leaking file descriptors.\n","    Raises\n","    ------\n","    IOError\n","        If the input file does not exist or cannot be read.\n","    ValueError\n","        The file contains an object array, but allow_pickle=False given.\n","    See Also\n","    --------\n","    save, savez, savez_compressed, loadtxt\n","    memmap : Create a memory-map to an array stored in a file on disk.\n","    lib.format.open_memmap : Create or load a memory-mapped ``.npy`` file.\n","    Notes\n","    -----\n","    - If the file contains pickle data, then whatever object is stored\n","      in the pickle is returned.\n","    - If the file is a ``.npy`` file, then a single array is returned.\n","    - If the file is a ``.npz`` file, then a dictionary-like object is\n","      returned, containing ``{filename: array}`` key-value pairs, one for\n","      each file in the archive.\n","    - If the file is a ``.npz`` file, the returned value supports the\n","      context manager protocol in a similar fashion to the open function::\n","        with load('foo.npz') as data:\n","            a = data['a']\n","      The underlying file descriptor is closed when exiting the 'with'\n","      block.\n","    Examples\n","    --------\n","    Store data to disk, and load it again:\n","    >>> np.save('/tmp/123', np.array([[1, 2, 3], [4, 5, 6]]))\n","    >>> np.load('/tmp/123.npy')\n","    array([[1, 2, 3],\n","           [4, 5, 6]])\n","    Store compressed data to disk, and load it again:\n","    >>> a=np.array([[1, 2, 3], [4, 5, 6]])\n","    >>> b=np.array([1, 2])\n","    >>> np.savez('/tmp/123.npz', a=a, b=b)\n","    >>> data = np.load('/tmp/123.npz')\n","    >>> data['a']\n","    array([[1, 2, 3],\n","           [4, 5, 6]])\n","    >>> data['b']\n","    array([1, 2])\n","    >>> data.close()\n","    Mem-map the stored array, and then access the second row\n","    directly from disk:\n","    >>> X = np.load('/tmp/123.npy', mmap_mode='r')\n","    >>> X[1, :]\n","    memmap([4, 5, 6])\n","    \"\"\"\n","    own_fid = False\n","    if isinstance(file, basestring):\n","        fid = open(file, \"rb\")\n","        own_fid = True\n","    elif is_pathlib_path(file):\n","        fid = file.open(\"rb\")\n","        own_fid = True\n","    else:\n","        fid = file\n","\n","    if encoding not in ('ASCII', 'latin1', 'bytes'):\n","        # The 'encoding' value for pickle also affects what encoding\n","        # the serialized binary data of NumPy arrays is loaded\n","        # in. Pickle does not pass on the encoding information to\n","        # NumPy. The unpickling code in numpy.core.multiarray is\n","        # written to assume that unicode data appearing where binary\n","        # should be is in 'latin1'. 'bytes' is also safe, as is 'ASCII'.\n","        #\n","        # Other encoding values can corrupt binary data, and we\n","        # purposefully disallow them. For the same reason, the errors=\n","        # argument is not exposed, as values other than 'strict'\n","        # result can similarly silently corrupt numerical data.\n","        raise ValueError(\"encoding must be 'ASCII', 'latin1', or 'bytes'\")\n","\n","    if sys.version_info[0] >= 3:\n","        pickle_kwargs = dict(encoding=encoding, fix_imports=fix_imports)\n","    else:\n","        # Nothing to do on Python 2\n","        pickle_kwargs = {}\n","\n","    try:\n","        # Code to distinguish from NumPy binary files and pickles.\n","        _ZIP_PREFIX = b'PK\\x03\\x04'\n","        N = len(format.MAGIC_PREFIX)\n","        magic = fid.read(N)\n","        # If the file size is less than N, we need to make sure not\n","        # to seek past the beginning of the file\n","        fid.seek(-min(N, len(magic)), 1)  # back-up\n","        if magic.startswith(_ZIP_PREFIX):\n","            # zip-file (assume .npz)\n","            # Transfer file ownership to NpzFile\n","            tmp = own_fid\n","            own_fid = False\n","            return NpzFile(fid, own_fid=tmp, allow_pickle=allow_pickle,\n","                           pickle_kwargs=pickle_kwargs)\n","        elif magic == format.MAGIC_PREFIX:\n","            # .npy file\n","            if mmap_mode:\n","                return format.open_memmap(file, mode=mmap_mode)\n","            else:\n","                return format.read_array(fid, allow_pickle=allow_pickle,\n","                                         pickle_kwargs=pickle_kwargs)\n","        else:\n","            # Try a pickle\n","            if not allow_pickle:\n","                raise ValueError(\"allow_pickle=False, but file does not contain \"\n","                                 \"non-pickled data\")\n","            try:\n","                return pickle.load(fid, **pickle_kwargs)\n","            except Exception:\n","                raise IOError(\n","                    \"Failed to interpret file %s as a pickle\" % repr(file))\n","    finally:\n","        if own_fid:\n","            fid.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SirzvtbqaLr1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WX0dw2UPZpiy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"28a05d23-8b71-489e-fdd1-d32ea024894d","executionInfo":{"status":"error","timestamp":1569381126221,"user_tz":240,"elapsed":476,"user":{"displayName":"Alexander Shypula","photoUrl":"","userId":"04633353775377489102"}}},"source":["del globals()[np.load.func_name]"],"execution_count":82,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-82-03674a030b9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'func_name'"]}]},{"cell_type":"code","metadata":{"id":"v7ZoB-hyBr_k","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"735e3aa5-b1f0-462b-8a63-273cf41b8306","executionInfo":{"status":"ok","timestamp":1569378813092,"user_tz":240,"elapsed":1053,"user":{"displayName":"Alexander Shypula","photoUrl":"","userId":"04633353775377489102"}}},"source":["\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n"],"execution_count":44,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H6I_yAV4EoTc","colab_type":"code","colab":{}},"source":["# !mkdir -p ~/.kaggle\n","# !cp kaggle.json ~/.kaggle/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"euHX9Po-Ctcl","colab_type":"code","colab":{}},"source":["# ! kaggle competitions download 11785-hw1-fall2019"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"furVdIRsDJeR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"b96e3c76-95d6-41d0-b1b6-27fe42c96b56","executionInfo":{"status":"ok","timestamp":1569378813093,"user_tz":240,"elapsed":1033,"user":{"displayName":"Alexander Shypula","photoUrl":"","userId":"04633353775377489102"}}},"source":["% cd drive/My\\ Drive/11-785"],"execution_count":47,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: 'drive/My Drive/11-785'\n","/content/drive/My Drive/11-785\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l4nlwnW9J8FC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":66},"outputId":"6c5b11c8-e304-4fb7-a26b-f9c878564ab1","executionInfo":{"status":"ok","timestamp":1569378814981,"user_tz":240,"elapsed":2914,"user":{"displayName":"Alexander Shypula","photoUrl":"","userId":"04633353775377489102"}}},"source":["! ls"],"execution_count":48,"outputs":[{"output_type":"stream","text":["11-785hw1p2-f19\t\thw1p2_float16%20tar.gz\t\t model_7_9_24.pt\n","11-785hw1p2-f19.tar.gz\thw1p2_float32.tar.gz\t\t preds_model_7_9_24.csv\n","dev_labels.npy.zip\thw1p2_sample_submission.csv.zip  train_labels.npy.zip\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5hWIJgiEIP2t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":115},"outputId":"83ea17dc-f198-4197-bf2c-9132068e14cd","executionInfo":{"status":"ok","timestamp":1569378950521,"user_tz":240,"elapsed":138446,"user":{"displayName":"Alexander Shypula","photoUrl":"","userId":"04633353775377489102"}}},"source":["! tar -xvf 11-785hw1p2-f19.tar.gz"],"execution_count":49,"outputs":[{"output_type":"stream","text":["./11-785hw1p2-f19/\n","./11-785hw1p2-f19/dev.npy\n","./11-785hw1p2-f19/test.npy\n","./11-785hw1p2-f19/train.npy\n","./11-785hw1p2-f19/dev_labels.npy\n","./11-785hw1p2-f19/train_labels.npy\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cd5ZODnwBQro","colab_type":"code","colab":{}},"source":["def pad_constant_central_pattern(x, kval_pre, kval_post):\n","    \"\"\"\n","    Takes one 2-dimensional array with the constant value of padding. \n","    Pads the instances with the given constant value while\n","    maintaining the array at the center of the padding.\n","\n","    Parameters: \n","    x (numpy.ndarray): 2-d numpy array.\n","    cval (numpy.int64): scalar quantity.\n","    \n","    Returns: \n","    numpy.ndarray: 3-dimensional int numpy array, (n, m, k).\n","    \"\"\"\n","    spectrogram = x\n","    \n","    # Input function dimension specification\n","\n","    \n","    assert(x.ndim == 2)\n","\n","    dim1 = x.shape[0] +  kval_pre + kval_post   # n\n","    dim2 = x.shape[1]\n","\n","    result = np.ones((dim1,dim2))\n","\n","    \n","    pad_above = kval_pre\n","    pad_below = kval_post\n","        \n","    pad_left = 0\n","    pad_right = 0\n","    \n","    n_add = ((pad_above, pad_below), (pad_left, pad_right))\n","\n","    result = np.pad(x , pad_width=n_add , mode = 'edge') \n","    \n","\n","    # Assert output function dimension specification\n","    assert(result.shape[0] == dim1)\n","    assert(result.shape[1] == dim2)\n","    \n","    return result"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qaH1ieKPBQrq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"0d80f960-09d4-4510-97fb-412dd21a4a7f","executionInfo":{"status":"ok","timestamp":1569378950522,"user_tz":240,"elapsed":138433,"user":{"displayName":"Alexander Shypula","photoUrl":"","userId":"04633353775377489102"}}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"5hupL4jDBQrs","colab_type":"code","colab":{}},"source":["from torch.utils import data\n","from sklearn.preprocessing import MultiLabelBinarizer\n","\n","class SpectrogramTrainDataset(data.Dataset):\n","    \"\"\"\n","\n","    Arguments:\n","        \n","    \"\"\"\n","\n","    def __init__(self, path, X_train_name, Y_train_name, transform=None, pre_padding = 0, post_padding = 0, frame_dim = 40):\n","        \n","        self.X_train = np.load(path + X_train_name)\n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        #self.X_test = np.load(path + X_test_name)\n","        \n","        self.Y_train = np.load(path + Y_train_name)\n","        #self.mlb = MultiLabelBinarizer(); \n","        #self.Y_train = self.mlb.fit_transform(np.load(path + Y_train_name))\n","        self.pre_padding = pre_padding\n","        self.post_padding = post_padding\n","        self.frame_dim = frame_dim\n","\n","    def __getitem__(self, index):\n","        \n","        utterance = self.X_train[index]\n","        Y = self.Y_train[index]\n","        \n","        slice_size = self.pre_padding + self.post_padding + 1\n","        dim1 = utterance.shape[0]\n","        dim2 = self.frame_dim * slice_size\n","        \n","        utterance = pad_constant_central_pattern(utterance, self.pre_padding, self.post_padding)\n","        \n","        i = random.randint(0, dim1 - 1)\n","        #x = torch.from_numpy(utterance[i]).type(torch.FloatTensor)\n","        y = Y[i]\n","        \n","        x = torch.from_numpy(utterance[i: i + slice_size].flatten()).type(torch.FloatTensor).to(self.device)\n","        #x = torch.from_numpy(np.random.randn(40*slice_size)).type(torch.FloatTensor)\n","        \n","        assert x.shape[0] == dim2\n","        \n","        return x, y\n","\n","    def __len__(self):\n","        return self.X_train.shape[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"24Qo0cliBQru","colab_type":"code","colab":{}},"source":["class SpectrogramTestDataset(data.Dataset):\n","    \"\"\"\n","\n","    Arguments:\n","        \n","    \"\"\"\n","\n","    def __init__(self, path, X_test_name, transform=None, pre_padding = 5, post_padding = 5, frame_dim = 40):\n","        \n","        \n","        self.pre_padding = pre_padding\n","        self.post_padding = post_padding\n","        self.frame_dim = frame_dim\n","        \n","        slice_size = self.pre_padding + self.post_padding + 1\n","        \n","        test = np.load(path + X_test_name)\n","        dim1 = sum([t.shape[0] for t in test])\n","        dim2 = self.frame_dim * slice_size\n","\n","        self.X_test = torch.empty(dim1, dim2).to(device)\n","\n","        X_test_index = 0\n","\n","        for utterance in test:\n","\n","            slice_size = self.pre_padding + self.post_padding + 1\n","            nframes = utterance.shape[0]\n","\n","            utterance = pad_constant_central_pattern(utterance, self.pre_padding, self.post_padding)\n","\n","            for i in range(nframes):\n","                self.X_test[X_test_index] = torch.from_numpy(utterance[i: i + slice_size].flatten()).type(torch.FloatTensor).to(device)\n","                X_test_index += 1\n","        \n","\n","    def __getitem__(self, index):\n","        \n","        x = self.X_test[index]\n","        \n","        return x\n","\n","    def __len__(self):\n","        return self.X_test.shape[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KrI8FTv3BQrx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"b74bb3b6-30f3-42cb-ede5-64563f3bf450","executionInfo":{"status":"ok","timestamp":1569378951890,"user_tz":240,"elapsed":139784,"user":{"displayName":"Alexander Shypula","photoUrl":"","userId":"04633353775377489102"}}},"source":["! ls 11-785hw1p2-f19/"],"execution_count":54,"outputs":[{"output_type":"stream","text":[" dev_labels.npy   test.npy\t   train_labels.npy\n"," dev.npy\t 'train (1).npy'   train.npy\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Um5sVQCzMbNA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3CiQzQZDVJ8N","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"55rPXOiNBQr1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":263},"outputId":"776deb47-3589-47cd-fe6a-3681dbf86954","executionInfo":{"status":"error","timestamp":1569379234837,"user_tz":240,"elapsed":433,"user":{"displayName":"Alexander Shypula","photoUrl":"","userId":"04633353775377489102"}}},"source":["train_data = SpectrogramTrainDataset('11-785hw1p2-f19/', \"train.npy\", \"train_labels.npy\", pre_padding=12, post_padding=5)\n"],"execution_count":58,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-58-cdb39d636a88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpectrogramTrainDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'11-785hw1p2-f19/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train_labels.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_padding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_padding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-52-627f0da12b5e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, X_train_name, Y_train_name, transform, pre_padding, post_padding, frame_dim)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_padding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_padding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mX_train_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#self.X_test = np.load(path + X_test_name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-57-9f6b7aa8fd4d>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*a, **k)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# modify the default parameters of np.load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp_load_old\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-55-9f6b7aa8fd4d>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*a, **k)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# modify the default parameters of np.load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp_load_old\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: <lambda>() got multiple values for keyword argument 'allow_pickle'"]}]},{"cell_type":"code","metadata":{"id":"rdp1y-K3BQr4","colab_type":"code","colab":{}},"source":["nworkers = multiprocessing.cpu_count()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hEO9nnndBQr7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"c7c8dbd8-c53c-4cf0-ffe3-269efb45c53e","executionInfo":{"status":"ok","timestamp":1569379241284,"user_tz":240,"elapsed":293,"user":{"displayName":"Alexander Shypula","photoUrl":"","userId":"04633353775377489102"}}},"source":["n_frames = 0\n","for utterance in train_data.X_train:\n","    n_frames+=utterance.shape[0]\n","print(n_frames)\n","print(n_frames/len(train_data.X_train))\n","\n","\n","weights = []\n","for utterance in train_data.X_train: \n","    weight = utterance.shape[0] / n_frames\n","    weights.append(weight)\n","\n"],"execution_count":60,"outputs":[{"output_type":"stream","text":["15388713\n","628.1107346938776\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W-CidatiBQr9","colab_type":"code","colab":{}},"source":["SpectrogramLoader = data.DataLoader(\n","    train_data, \n","    batch_size=1000,      # Batch size\n","    shuffle=True,      # Shuffles the dataset at every epoch\n","    pin_memory=False,   # Copy data to CUDA pinned memory\n","                       # so that they can be transferred to the GPU very fast\n","    num_workers=nworkers      # Number of worker processes for loading data.\n","                       # If zero, use the current process (blocks until data are loaded)\n","                       # Otherwise fork/spawn new processes (asynchronous load)\n","                       # Spawning new processes can be problematic on Windows, see:\n","                       # https://pytorch.org/docs/stable/notes/windows.html#usage-multiprocessing\n",")\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ysPtMg-6BQsA","colab_type":"code","colab":{}},"source":["train_size = train_data.__len__()\n","\n","val_size, train_size = int(0.20 * train_size), int(0.80 * train_size) # 80 / 20 train-val split\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jC6-vqBtBQsE","colab_type":"code","colab":{}},"source":["train_size = train_data.__len__()\n","\n","val_size, train_size = int(0.20 * train_size), int(0.80 * train_size) # 80 / 20 train-val split\n","# print(\"val size is {}\".format(val_size))\n","# print(\"train size is {}\".format(train_size))\n","\n","train_weights = weights[val_size: val_size+train_size] \n","val_weights = weights[0:val_size]\n","train_sampler = torch.utils.data.sampler.WeightedRandomSampler(train_weights, len(train_weights), replacement = False)\n","val_sampler = torch.utils.data.sampler.WeightedRandomSampler(val_weights, len(val_weights), replacement = False)\n","# print(\"size of weights\", len(weights))\n","# print(\"size of train weights\", len(train_weights))\n","# print(\"size of val weights\", len(val_weights))\n","# print(\"size of train + val weights\", len(val_weights) + len(train_weights))\n","\n","#test_size = test_data.test_data.shape[0]\n","\n","batch_size = 5000\n","\n","# Add dataset to dataloader that handles batching\n","train_loader = torch.utils.data.DataLoader(train_data, \n","                                           batch_size=batch_size,\n","                                           sampler=train_sampler)\n","\n","val_loader = torch.utils.data.DataLoader(train_data, \n","                                           batch_size=batch_size, \n","                                           sampler=val_sampler)\n","\n","\n","'''test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)'''\n","\n","# Setup metric class\n","Metric = namedtuple('Metric', ['loss', 'train_error', 'val_error'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M5TISy__LoYC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hJkcGqZJLne-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":163},"outputId":"e3d8aea2-f2c1-4ccd-a362-e8ca2a06d66b","executionInfo":{"status":"ok","timestamp":1569379265653,"user_tz":240,"elapsed":471,"user":{"displayName":"Alexander Shypula","photoUrl":"","userId":"04633353775377489102"}}},"source":["class PhonemeModel(nn.Module):\n","    def __init__(self):\n","        super(PhonemeModel, self).__init__()\n","        self.fc1 = nn.Linear((train_data.pre_padding + train_data.post_padding + 1) * train_data.frame_dim, 1500)\n","        self.fc2 = nn.Linear(1500, 1500)\n","        self.fc3 = nn.Linear(1500, 1500)\n","        self.fc4 = nn.Linear(1500, 1500)\n","        self.fc5 = nn.Linear(1500, 1500)\n","        self.fc6 = nn.Linear(1500, 138)\n","        \n","        self.bn1 = nn.BatchNorm1d(1500)\n","    \n","    def forward(self, x):\n","        \n","        x = self.bn1(F.relu(self.fc1(x)))\n","        x = self.bn1(F.relu(self.fc2(x)))\n","        x = self.bn1(F.relu(self.fc3(x)))\n","        x = self.bn1(F.relu(self.fc4(x)))\n","        x = self.bn1(F.relu(self.fc5(x)))\n","        x = F.log_softmax(self.fc6(x))\n","        return x\n"," \n","print(PhonemeModel())"],"execution_count":66,"outputs":[{"output_type":"stream","text":["PhonemeModel(\n","  (fc1): Linear(in_features=440, out_features=1500, bias=True)\n","  (fc2): Linear(in_features=1500, out_features=1500, bias=True)\n","  (fc3): Linear(in_features=1500, out_features=1500, bias=True)\n","  (fc4): Linear(in_features=1500, out_features=1500, bias=True)\n","  (fc5): Linear(in_features=1500, out_features=1500, bias=True)\n","  (fc6): Linear(in_features=1500, out_features=138, bias=True)\n","  (bn1): BatchNorm1d(1500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aKVTlWV3Q0s8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZOciQnu9BQsI","colab_type":"code","colab":{}},"source":["'''\n","\n","class PhonemeModel(nn.Module):\n","    def __init__(self):\n","        super(PhonemeModel, self).__init__()\n","        self.fc1 = nn.Linear((train_data.pre_padding + train_data.post_padding + 1) * train_data.frame_dim, 1000)\n","        self.fc2 = nn.Linear(1000, 400)\n","        self.fc3 = nn.Linear(400, 138)\n","    \n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = F.log_softmax(self.fc3(x))\n","        return x\n","print(PhonemeModel())\n","\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WZcVaBA-BQsK","colab_type":"code","colab":{}},"source":["#import torch.optim as optim\n","\n","#criterion = nn.CrossEntropyLoss()\n","#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C2_1HT9cBQsN","colab_type":"code","colab":{}},"source":["input_size = (train_data.pre_padding + train_data.post_padding + 1) * train_data.frame_dim"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X47lq_CtBQsP","colab_type":"code","colab":{}},"source":["def inference(model, loader, n_members):\n","    correct = 0\n","    for data, label in loader:\n","        X = Variable(data.view(-1, input_size)).to(device)\n","        Y = Variable(label).to(device)\n","        out = model(X).to(device)\n","        pred = out.data.max(1, keepdim=True)[1]\n","        predicted = pred.eq(Y.data.view_as(pred))\n","        correct += predicted.sum()\n","    return correct.item() / n_members\n","\n","\n","class Trainer():\n","    \"\"\" \n","    A simple training cradle\n","    \"\"\"\n","    \n","    def __init__(self, model, optimizer, load_path=None):\n","        self.model = model\n","        if load_path is not None:\n","            self.model = torch.load(load_path)\n","        self.optimizer = optimizer\n","            \n","    def save_model(self, path):\n","        torch.save(self.model.state_dict(), path)\n","\n","    def run(self, epochs):\n","        print(\"Start Training...\")\n","        self.metrics = []\n","        for e in range(epochs):\n","            scheduler.step()\n","            epoch_loss = 0\n","            correct = 0\n","            for batch_idx, (data, label) in enumerate(train_loader):\n","                self.optimizer.zero_grad()\n","                X = Variable(data.view(-1, input_size)).to(device)\n","                Y = Variable(label).to(device)\n","                #pdb.set_trace()\n","                out = self.model(X).to(device)\n","                pred = out.data.max(1, keepdim=True)[1]\n","                predicted = pred.eq(Y.data.view_as(pred))\n","                correct += predicted.sum()\n","                loss = F.nll_loss(out, Y)\n","                \n","#                 print(\"X shape is: {}\".format(X.shape))\n","#                 print(\"Y shape is: {}\".format(Y.shape))\n","#                 print(\"Out shape is: {}\".format(out.shape))\n","#                 print(\"Pred shape is: {}\".format(pred.shape))\n","                #print(\"Pred is: {}\".format(pred))\n","                #print(\"Pred[0] is: {}\".format(pred[0]))\n","                #print(\"Loss is: {}\".format(loss))\n","                \n","                loss.backward()\n","                self.optimizer.step()\n","                epoch_loss += loss.item()\n","            total_loss = epoch_loss/train_size\n","            train_error = 1.0 - correct/train_size\n","            val_error = 1.0 - inference(self.model, val_loader, val_size)\n","            print(\"epoch: {0}, loss: {1:.8f}\".format(e+1, total_loss))\n","            self.metrics.append(Metric(loss=total_loss, \n","                                  train_error=train_error,\n","                                  val_error=val_error))\n","         "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8CLu1Sa9BQsR","colab_type":"code","colab":{}},"source":["def init_randn(m):\n","    if type(m) == nn.Linear:\n","        m.weight.data.normal_(0,1)\n","\n","# We first initialize a Fashion Object and initialize the parameters \"normally\".\n","model = PhonemeModel().to(device)\n","AdamOptimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n","scheduler = torch.optim.lr_scheduler.StepLR(AdamOptimizer, step_size=4, gamma=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hQBzeJCaBQsT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":395},"outputId":"01215eb4-2ab3-43eb-fa19-66a3cb4cee0e","executionInfo":{"status":"ok","timestamp":1569379564353,"user_tz":240,"elapsed":290723,"user":{"displayName":"Alexander Shypula","photoUrl":"","userId":"04633353775377489102"}}},"source":["modelTrainer = Trainer(model, AdamOptimizer)\n","modelTrainer.run(20)"],"execution_count":70,"outputs":[{"output_type":"stream","text":["Start Training...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 1, loss: 0.00089017\n","epoch: 2, loss: 0.00075468\n","epoch: 3, loss: 0.00071252\n","epoch: 4, loss: 0.00069054\n","epoch: 5, loss: 0.00068708\n","epoch: 6, loss: 0.00068246\n","epoch: 7, loss: 0.00067710\n","epoch: 8, loss: 0.00067371\n","epoch: 9, loss: 0.00067433\n","epoch: 10, loss: 0.00067154\n","epoch: 11, loss: 0.00067112\n","epoch: 12, loss: 0.00067309\n","epoch: 13, loss: 0.00067089\n","epoch: 14, loss: 0.00067034\n","epoch: 15, loss: 0.00067146\n","epoch: 16, loss: 0.00066858\n","epoch: 17, loss: 0.00067251\n","epoch: 18, loss: 0.00067099\n","epoch: 19, loss: 0.00067228\n","epoch: 20, loss: 0.00067281\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jitcjUY-BQsV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":281},"outputId":"bb8734ad-62b1-4fd4-872c-d9e64e1b35f5","executionInfo":{"status":"ok","timestamp":1569379564354,"user_tz":240,"elapsed":289737,"user":{"displayName":"Alexander Shypula","photoUrl":"","userId":"04633353775377489102"}}},"source":["def training_plot(metrics):\n","    plt.figure(1)\n","    plt.plot([m.loss for m in metrics], 'b')\n","    plt.title('Training Loss')\n","    plt.show()\n","\n","training_plot(modelTrainer.metrics)"],"execution_count":71,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAZAAAAEICAYAAABxiqLiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"KTYtgukfBQsY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":281},"outputId":"828f00f1-6d7a-4256-e866-f219059285a7","executionInfo":{"status":"ok","timestamp":1569379564670,"user_tz":240,"elapsed":289305,"user":{"displayName":"Alexander Shypula","photoUrl":"","userId":"04633353775377489102"}}},"source":["def training_plot(metrics):\n","    plt.figure(1)\n","    plt.plot([m.val_error for m in metrics], 'b')\n","    plt.title('Val Error')\n","    plt.show()\n","\n","training_plot(modelTrainer.metrics)"],"execution_count":72,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIEr6IiIFRElfRKSA/H/lIoRX1UkTfAAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"gMMHPjraBQsc","colab_type":"code","colab":{}},"source":["test_data = SpectrogramTestDataset('11-785hw1p2-f19/', \"test.npy\", pre_padding=5, post_padding=5)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4BdHo_l9XoCh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"df6fd1b0-a163-4431-a600-c5a58aae73cf","executionInfo":{"status":"ok","timestamp":1569381523522,"user_tz":240,"elapsed":2542,"user":{"displayName":"Alexander Shypula","photoUrl":"","userId":"04633353775377489102"}}},"source":["test_loader = torch.utils.data.DataLoader(test_data, \n","                                           batch_size=5000)\n","\n","pred = []\n","for data in test_loader:\n","    X = Variable(data.view(-1, 440))\n","    out = modelTrainer.model(X)\n","    pred.append(out.data.max(1, keepdim=True)[1].cpu().numpy())\n","    #pred.append(out.data.max(1, keepdim=True)[1])\n","pred = np.concatenate(np.array(pred))"],"execution_count":100,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"B76aKjCZBQsl","colab_type":"code","colab":{}},"source":["import pandas as pd\n","df = pd.DataFrame(pred, columns=[\"label\"])\n","df.to_csv('preds_model_9_9_24.csv', index_label = \"id\", index=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Jn_nN0LBQsm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"50734657-b37a-41ec-f2c1-f8d09da9f202","executionInfo":{"status":"ok","timestamp":1569381527376,"user_tz":240,"elapsed":454,"user":{"displayName":"Alexander Shypula","photoUrl":"","userId":"04633353775377489102"}}},"source":["torch.save(modelTrainer.model, \"model_9_9_24.pt\")"],"execution_count":102,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type PhonemeModel. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"P08smhv1BQso","colab_type":"code","colab":{},"outputId":"5fc93baa-ce32-42db-9f79-fdb36de4bfcd"},"source":["def training_plot(metrics):\n","    plt.figure(1)\n","    plt.plot([m.val_error for m in metrics], 'b')\n","    plt.title('Val Error')\n","    plt.show()\n","\n","training_plot(modelTrainer.metrics)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"rP8iltVUBQsq","colab_type":"code","colab":{}},"source":["import pdb\n","def inference(model, loader, n_members):\n","    correct = 0\n","    for data, label in loader:\n","        X = Variable(data.view(-1, input_size)).to(device)\n","        Y = Variable(label).to(device)\n","        out = model(X).to(device)\n","        pred = out.data.max(1, keepdim=True)[1]\n","        predicted = pred.eq(Y.data.view_as(pred))\n","        correct += predicted.sum()\n","        pdb.set_trace()\n","    return correct / n_members\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W4D6K9fXBQss","colab_type":"code","colab":{}},"source":["for epoch in range(2):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 2000 == 1999:    # print every 2000 mini-batches\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 2000))\n","            running_loss = 0.0\n","\n","print('Finished Training'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dGL7EPvRBQst","colab_type":"text"},"source":["## Random examples from the Fashion-MNIST dataset"]},{"cell_type":"markdown","metadata":{"id":"nFNFqW3NBQsu","colab_type":"text"},"source":["## Build a model\n","\n","As we are more focussed on evaluating how the different optimization methods perform, we'll be constructing a very simple feedforward network."]},{"cell_type":"markdown","metadata":{"id":"7zsvA-OrBQsu","colab_type":"text"},"source":["## A Simple Optimizer in PyTorch\n","\n","The most simple optimization method is to update the network parameters by adding the negative of the gradient scaled by a fixed learning rate $\\eta$.\n","\n","$$ \\textbf{W'} \\leftarrow \\textbf{W} - \\eta \\nabla L(\\textbf{W}) $$\n","\n","PyTorch provides us a very simple and expressive API for creating custom optimizers. An optimizer in PyTorch subclasses `torch.optim.Optimizer` and is required to specify two methods.\n","\n","`__init__`: Must call the superclass `__init__` and provide a list of network parameters, `params`, to optimize and a dictionary of default values provided to each parameter group, `defaults`. \n","\n","`step`: Performs an update on the network parameters. \n","\n","The meat of your optimizer logic lies in the `step` method. In this method you should update your model parameters with the help of some useful internal datastructures. Let's define these to make the following code more clear.\n","\n","`self.param_groups`: When you initialize an optimizer object, you are required to provide the list of parameter objects to be optimized. In the case of `FashionModel`, there are 6 parameters -- each `Linear` layer has a weight matrix parameter and a bias vector. All of these 6 parameters are considered within a single `param_group`. This `group` will be a dictionary with an entry `params` that contains an iterable of all 6 parameters, as well as entries for all `defaults`. These `defaults` are generally useful for storing small values like hyperparameters that are standard across all parameter groups. There are more advanced cases where it can come in handy to have different values for certain entities depending on the `param_group`. \n","\n","`self.state`: This maintains state for a given parameter. Essentially it maps a parameter to a dictionary of data that you want to keep track of. This is useful in cases where you want to keep state on a per-parameter basis.\n","\n","**IMPORTANT**: Unlike most other use cases in PyTorch, operations on parameters and state data should be done inplace. This ensures that the updated parameters are not updated copies of the original. In the following sample implementations, you may see some unfamiliar operations. Functions like `torch.add_` and `torch.mul_` are just inplace analogues of standard PyTorch functions. See http://pytorch.org/docs/master/torch.html for further details.\n","\n","\n","## Let's write our *Trainer*"]},{"cell_type":"code","metadata":{"id":"e-gknI9uBQsw","colab_type":"code","colab":{}},"source":["train_size = train_data.train_data.shape[0]\n","val_size, train_size = int(0.20 * train_size), int(0.80 * train_size) # 80 / 20 train-val split\n","test_size = test_data.test_data.shape[0]\n","batch_size = 100\n","\n","# Add dataset to dataloader that handles batching\n","train_loader = torch.utils.data.DataLoader(train_data, \n","                                           batch_size=batch_size,\n","                                           sampler=torch.utils.data.sampler.SubsetRandomSampler(np.arange(val_size, val_size+train_size)))\n","val_loader = torch.utils.data.DataLoader(train_data, \n","                                           batch_size=batch_size, \n","                                           sampler=torch.utils.data.sampler.SubsetRandomSampler(np.arange(0, val_size)))\n","\n","\n","# Setup metric class\n","Metric = namedtuple('Metric', ['loss', 'train_error', 'val_error'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z5WbobL5BQsy","colab_type":"text"},"source":["# How to adjust Learning Rate\n","\n","`torch.optim.lr_scheduler` provides several methods to adjust the learning rate based on the number of epochs. Learning rate scheduling should be applied after optimizer’s update. See https://pytorch.org/docs/stable/optim.html for details."]},{"cell_type":"code","metadata":{"id":"oLd6aANqBQsz","colab_type":"code","colab":{}},"source":["def inference(model, loader, n_members):\n","    correct = 0\n","    for data, label in loader:\n","        X = Variable(data.view(-1, 440))\n","        Y = Variable(label)\n","        out = model(X)\n","        pred = out.data.max(1, keepdim=True)[1]\n","        predicted = pred.eq(Y.data.view_as(pred))\n","        correct += predicted.sum()\n","    return correct.numpy() / n_members\n","\n","class Trainer():\n","    \"\"\" \n","    A simple training cradle\n","    \"\"\"\n","    \n","    def __init__(self, model, optimizer, load_path=None):\n","        self.model = model\n","        if load_path is not None:\n","            self.model = torch.load(load_path)\n","        self.optimizer = optimizer\n","            \n","    def save_model(self, path):\n","        torch.save(self.model.state_dict(), path)\n","\n","    def run(self, epochs):\n","        print(\"Start Training...\")\n","        self.metrics = []\n","        for e in range(n_epochs):\n","            scheduler.step()\n","            epoch_loss = 0\n","            correct = 0\n","            for batch_idx, (data, label) in enumerate(train_loader):\n","                self.optimizer.zero_grad()\n","                X = Variable(data.view(-1, 440))\n","                Y = Variable(label)\n","                out = self.model(X)\n","                pred = out.data.max(1, keepdim=True)[1]\n","                predicted = pred.eq(Y.data.view_as(pred))\n","                correct += predicted.sum()\n","                loss = F.nll_loss(out, Y)\n","                loss.backward()\n","                self.optimizer.step()\n","                epoch_loss += loss.item()\n","            total_loss = epoch_loss/train_size\n","            train_error = 1.0 - correct/train_size\n","            val_error = 1.0 - inference(self.model, val_loader, val_size)\n","            print(\"epoch: {0}, loss: {1:.8f}\".format(e+1, total_loss))\n","            self.metrics.append(Metric(loss=total_loss, \n","                                  train_error=train_error,\n","                                  val_error=val_error))\n","         "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BNrxceIsBQs1","colab_type":"code","colab":{}},"source":["### LET'S TRAIN ###\n","\n","# A function to apply \"normal\" distribution on the parameters\n","def init_randn(m):\n","    if type(m) == nn.Linear:\n","        m.weight.data.normal_(0,1)\n","\n","# We first initialize a Fashion Object and initialize the parameters \"normally\".\n","normalmodel = PhonemeModel()\n","normalmodel.apply(init_randn)\n","\n","n_epochs = 100\n","'''\n","print(\"SGD OPTIMIZER\")\n","SGDOptimizer = torch.optim.SGD(normalmodel.parameters(), lr=0.01)\n","scheduler = torch.optim.lr_scheduler.StepLR(SGDOptimizer, step_size=0.01, gamma=0.1)\n","sgd_trainer = Trainer(normalmodel, SGDOptimizer)\n","sgd_trainer.run(n_epochs)\n","sgd_trainer.save_model('./sgd_model.pt')\n","print('')\n","'''\n","\n","print(\"ADAM OPTIMIZER\")\n","normalmodel = PhonemeModel()\n","normalmodel.apply(init_randn)\n","AdamOptimizer = torch.optim.Adam(normalmodel.parameters(), lr=0.001)\n","scheduler = torch.optim.lr_scheduler.StepLR(AdamOptimizer, step_size=4, gamma=0.1)\n","adam_trainer = Trainer(normalmodel, AdamOptimizer)\n","adam_trainer.run(n_epochs)\n","adam_trainer.save_model('./adam_model.pt')\n","print('')\n","\n","\n","print(\"RMSPROP OPTIMIZER\")\n","normalmodel = PhonemeModel()\n","normalmodel.apply(init_randn)\n","RMSPropOptimizer = torch.optim.RMSprop(normalmodel.parameters(), lr=0.001)\n","scheduler = torch.optim.lr_scheduler.StepLR(RMSPropOptimizer, step_size=4, gamma=0.1)\n","rms_trainer = Trainer(normalmodel, RMSPropOptimizer)\n","rms_trainer.run(n_epochs)\n","rms_trainer.save_model('./rmsprop_model.pt')\n","print('')\n","\n","\n","### TEST ###\n","model = PhonemeModel()\n","model.load_state_dict(torch.load('./sgd_model.pt'))\n","test_acc = inference(model, test_loader, test_size)\n","print(\"Test accuracy of model optimizer with SGD: {0:.2f}\".format(test_acc * 100))\n","\n","model = PhonemeModel()\n","model.load_state_dict(torch.load('./adam_model.pt'))\n","test_acc = inference(model, test_loader, test_size)\n","print(\"Test accuracy of model optimizer with Adam: {0:.2f}\".format(test_acc * 100))\n","\n","model = PhonemeModel()\n","model.load_state_dict(torch.load('./rmsprop_model.pt'))\n","test_acc = inference(model, test_loader, test_size)\n","print(\"Test accuracy of model optimizer with RMSProp: {0:.2f}\".format(test_acc * 100))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wvWfR1brBQs2","colab_type":"code","colab":{}},"source":["model = PhonemeModel()\n","model.load_state_dict(torch.load('./rmsprop_model.pt'))\n","\n","#value = torch.from_numpy(x_train[example_index])\n","\n","# then put it on the GPU, make it float and insert a fake batch dimension\n","arrays = [array for array in train_data.X_test]\n","test_value = Variable(torch.from_numpy(np.concatenate(arrays)))\n","test_value = test_value.float()\n","test_value = test_value.unsqueeze(0)\n","\n","# pass it through the model\n","prediction = model(test_value)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fPilYg1PBQs4","colab_type":"code","colab":{}},"source":["### VISUALIZATION ###\n","def training_plot(metrics):\n","    plt.figure(1)\n","    plt.plot([m.loss for m in metrics], 'b')\n","    plt.title('Training Loss')\n","    plt.show()\n","\n","training_plot(sgd_trainer.metrics)\n","training_plot(adam_trainer.metrics)\n","training_plot(rms_trainer.metrics)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x71SZjggBQs6","colab_type":"text"},"source":["## Parameter Initialization\n","\n","While training a network, the initial value of the weights plays a significant role. In the extreme case, an oracle could just set the weights directly to values that minimize the objective function, and in practical cases a good initialization can bring us to a more favorable starting position in the parameter space. \n","\n","This raises the question of how to choose these weights. \n","\n","- What happens if all the weights are set to zero? The gradients become zero, and the network finds itself without a direction. \n","- What if all of them are set to the same non-zero value? Although the gradients are no longer zero, each neuron has the same weight and follows the same gradient. Such neurons will continue to have the same value, since they're identical. \n","\n","So any initialization scheme must break this symmetry somehow, and randomly initializing the weights is a first step in that direction.\n","\n","Let's begin with creating a weight initialization function that samples from **N(0,1)**. A clean way of initializing the weights is to access the network parameters by traversing all modules inside the network, and then applying the desired initialization. This method also allows us to encapsulate all the initializations into a single function."]},{"cell_type":"code","metadata":{"id":"7vpJDdaxBQs6","colab_type":"code","colab":{}},"source":["def init_randn(m):\n","    if type(m) == nn.Linear:\n","        m.weight.data.normal_(0,1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7gkQYLlFBQs9","colab_type":"text"},"source":["Now let's use this scheme to initialize the network.\n","\n","Note that *apply(fn)* applies the function *fn* recursively to every submodule (as returned by .children()) as well as self. Also, since it is applied to itself as well, you must take care to select the appropriate type of module *m* and apply the initialization to it."]},{"cell_type":"code","metadata":{"scrolled":false,"id":"LeN-ciLcBQs9","colab_type":"code","colab":{}},"source":["normalmodel = FashionModel()\n","normalmodel.apply(init_randn)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GfmZ5jn6BQs_","colab_type":"text"},"source":["## Custom initializations\n","\n","We could also choose a different way to initialize the weights, where you explicitly copy some values into the weights."]},{"cell_type":"code","metadata":{"id":"nVvDt_7nBQs_","colab_type":"code","colab":{}},"source":["def init_custom(m):\n","    if type(m) == nn.Linear:\n","        rw = torch.randn(m.weight.data.size())\n","        m.weight.data.copy_(rw)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZgmLiZUABQtB","colab_type":"text"},"source":["Now let's use this initialization scheme to implement Xavier initialization. \n","\n","Xavier initialization is a way of initializing the weights such that the variance of the inputs is the same as the variance of the outputs. At each layer, the fan_in and fan_out (i.e. input connections and output connections) might be different. To calculate the variance, you will multiply each weight with the inputs. Evidently, if the number of inputs is less, they will need to be multiplied with higher weights so that they can sum up to the product of a larger number of outputs with smaller weights. This is the intuition behind Xavier initialization.\n"]},{"cell_type":"code","metadata":{"id":"myIhwBl6BQtC","colab_type":"code","colab":{}},"source":["def init_xavier(m):\n","    if type(m) == nn.Linear:\n","        fan_in = m.weight.size()[1]\n","        fan_out = m.weight.size()[0]\n","        std = np.sqrt(2.0 / (fan_in + fan_out))\n","        m.weight.data.normal_(0,std)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z_7hraAfBQtF","colab_type":"code","colab":{}},"source":["xaviermodel = FashionModel()\n","xaviermodel.apply(init_xavier)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r9Ijf_Z8BQtH","colab_type":"code","colab":{}},"source":["### LET'S TRAIN ###\n","n_epochs = 3\n","\n","print(\"NORMAL INIT WEIGHTS\")\n","AdamOptimizer = torch.optim.Adam(normalmodel.parameters(), lr=0.001)\n","normal_trainer = Trainer(normalmodel, AdamOptimizer)\n","normal_trainer.run(n_epochs)\n","normal_trainer.save_model('./normal_model.pt')\n","print('')\n","\n","\n","print(\"XAVIER INIT WEIGHTS\")\n","AdamOptimizer = torch.optim.Adam(xaviermodel.parameters(), lr=0.001)\n","xavier_trainer = Trainer(xaviermodel, AdamOptimizer)\n","xavier_trainer.run(n_epochs)\n","xavier_trainer.save_model('./xavier_model.pt')\n","print('')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DzI4ZQ2VBQtJ","colab_type":"code","colab":{}},"source":["### VISUALIZATION ###\n","def training_plot(metrics):\n","    plt.figure(1)\n","    plt.plot([m.loss for m in metrics], 'b')\n","    plt.title('Training Loss')\n","    plt.show()\n","\n","training_plot(normal_trainer.metrics)\n","training_plot(xavier_trainer.metrics)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5NQB7-hBBQtK","colab_type":"text"},"source":["## Using pretrained weights\n","\n","In the previous section we saw that initializations can start the training from a good spot. In addition to these schemes, you might also need to have specific methods to initialize the weights in different layers. For example, you might want to use a pretrained model like Alexnet to give your network a head start for visual recognition tasks. Let's load the pretrained Alexnet model and see how it works."]},{"cell_type":"code","metadata":{"id":"dC8hqhqSBQtL","colab_type":"code","colab":{}},"source":["alexnet_model = models.alexnet(pretrained=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-HysMAnmBQtP","colab_type":"text"},"source":["## Adding Momentum\n","\n","We can make use of the `self.state` data-structure to maintain a copy of an accumulated gradient that we also decay at each step. Once again we use inplace operations to avoid unneccesary buffer allocation. Recall a standard update with momentum given decay rate $\\mu$.\n","\n","$$ \\begin{align}\n","\\textbf{V'} &= \\mu \\textbf{V} - \\eta \\nabla L(\\textbf{W})\\\\\n","\\textbf{W'} &= \\textbf{W} + \\textbf{V'}\\\\\n","\\end{align}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"Dnq4DoDtBQtQ","colab_type":"text"},"source":["## Batch Normalization\n","\n","Batch normalization is a relatively simple but significant improvement in training neural networks. In machine learning, *covariate shift* is a phenomenon in which the covariate distribution is non-stationary over the course of training. This is a common phenomenon in online learning. When training a neural network on a fixed dataset, there is no covariate shift (excluding sample noise from minibatch approximation), but the distribution of individual node and layer activity shifts as the network parameters are updated. As an abstraction, we can consider each node's activity to be a covariate of the following nodes in the network. Thus we can think of the non-stationarity of node (and layer) activations as a sort of *internal covariate shift*. \n","\n","Why is internal covariate shift a problem? Each subsequent layer has to account for a shifting distribution of its inputs. For saturating non-linearities the problem becomes even more dire, as the shift in activity will more likely place the unit output in the saturated region of the non-linearity.\n","\n"]},{"cell_type":"code","metadata":{"id":"zrCPLxv8BQtQ","colab_type":"code","colab":{}},"source":["class BatchNorm(nn.Module):\n","\n","    def __init__(self, num_features):\n","        super(BatchNorm, self).__init__()\n","        self.num_features = num_features\n","        self.affine = affine\n","        self.weight = Parameter(torch.Tensor(num_features))\n","        self.bias = Parameter(torch.Tensor(num_features))\n","        self.register_buffer('running_mean', torch.zeros(num_features))\n","        self.register_buffer('running_var', torch.ones(num_features))\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        self.running_mean.zero_()\n","        self.running_var.fill_(1)\n","        self.weight.data.uniform_()\n","        self.bias.data.zero_()\n","\n","    def forward(self, x):\n","        pass"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WCEaDfP_BQtS","colab_type":"text"},"source":["## Overfitting\n","Deep neural networks contain multiple non-linear hidden layers and this makes them very\n","expressive models that can learn very complicated relationships between their inputs and\n","outputs. With limited training data, however, many of these complicated relationships\n","will be the result of sampling noise, so they will exist in the training set but not in real\n","test data even if it is drawn from the same distribution. This leads to overfitting and many\n","methods have been developed for reducing it.\n","\n","## Dropout\n","Dropout is a regularization technique for reducing overfitting in neural networks by preventing complex co-adaptations on training data. It is a very efficient way of performing model averaging with neural networks. The term \"dropout\" refers to dropping out units in a neural network.\n","\n","## Regularization (weight_decay)\n","\n","Weight decay specifies regularization in the neural network.\n","During training, a regularization term is added to the network's loss to compute the backpropagation gradient. The weight decay value determines how dominant this regularization term will be in the gradient computation.\n","\n","As a rule of thumb, the more training examples you have, the weaker this term should be. The more parameters you have the higher this term should be.\n"]},{"cell_type":"code","metadata":{"id":"yrYv37OLBQtU","colab_type":"code","colab":{}},"source":["class FashionModel_Tricks(nn.Module):\n","    \n","    def __init__(self):\n","        super(FashionModel_Tricks, self).__init__()\n","        self.fc1 = nn.Linear(784, 64)\n","        self.bnorm1 = nn.BatchNorm1d(64)\n","        self.dp1 = nn.Dropout(p=0.2)\n","        self.fc2 = nn.Linear(64, 32)\n","        self.bnorm2 = nn.BatchNorm1d(32)\n","        self.dp2 = nn.Dropout(p=0.1)\n","        self.fc3 = nn.Linear(32, 10)\n","    \n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = self.dp1(self.bnorm1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.dp2(self.bnorm2(x))\n","        x = F.log_softmax(self.fc3(x))\n","        return x\n","print(FashionModel_Tricks())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mLMDXNmVBQtW","colab_type":"code","colab":{}},"source":["### TRAIN MODELS WITH BATCHNORM AND DROPOUT ###\n","n_epochs = 10\n","\n","model = FashionModel_Tricks()\n","optimizer = torch.optim.SGD(model.parameters(), lr = 0.001, momentum = 0.9, weight_decay = 0.001)\n","btrainer = Trainer(model, optimizer)\n","btrainer.run(n_epochs)\n","btrainer.save_model('./dropout-batchnorm_optimized_model.pt')\n","\n","training_plot(btrainer.metrics)\n","\n","print('')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XJ8fpqNBBQtY","colab_type":"text"},"source":["## Gradient Clipping\n","\n","During experimentation, once the gradient value grows extremely large, it causes an overflow (i.e. NaN) which is easily detectable at runtime or in a less extreme situation, the Model starts overshooting past our Minima; this issue is called the Gradient Explosion Problem.\n","\n","Gradient clipping will ‘clip’ the gradients or cap them to a Threshold value to prevent the gradients from getting too large."]},{"cell_type":"code","metadata":{"id":"1Gsd_XUeBQtZ","colab_type":"code","colab":{}},"source":["#Gradient Clipping \n","# `clip_grad_norm` helps prevent the exploding gradient problem. To be used before optimizer.step()during training\n","torch.nn.utils.clip_grad_norm(model.parameters(), 0.25)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vYDkkKmVBQta","colab_type":"text"},"source":["## Annealing Learning Rate\n","In training deep networks, it is usually helpful to anneal the learning rate over time. Good intuition to have in mind is that with a high learning rate, the system contains too much kinetic energy and the parameter vector bounces around chaotically, unable to settle down into deeper, but narrower parts of the loss function. Knowing when to decay the learning rate can be tricky: Decay it slowly and you’ll be wasting computation bouncing around chaotically with little improvement for a long time. But decay it too aggressively and the system will cool too quickly, unable to reach the best position it can. One way of doing it is using step decay. Step decay schedule drops the learning rate by a factor every few epochs. The mathematical form of step decay is:\n","\n","$$\\eta = \\eta_0 * drop^{\\floor ( \\frac{epoch}{epochs\\_drop})}$$"]},{"cell_type":"code","metadata":{"id":"KmI0kI30BQta","colab_type":"code","colab":{}},"source":["def step_decay(epoch):\n","    initial_lrate = 0.1\n","    drop = 0.5\n","    epochs_drop = 10.0\n","    lrate = initial_lrate * math.pow(drop,  \n","           math.floor((1+epoch)/epochs_drop))\n","    return lrate"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"968UMvFABQtc","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U7UJtS2ZBUtn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}