{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "\n",
    "from torchtext.data import TabularDataset, Field, Iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab\n",
    "from torch import optim \n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import time\n",
    "from collections import namedtuple\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilized this tutorial : https://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/\n",
    "# https://medium.com/@sonicboom8/sentiment-analysis-with-variable-length-sequences-in-pytorch-6241635ae130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2Label = \\\n",
    "{0: 'Miscellaneous',\n",
    " 1: 'Video games',\n",
    " 2: 'Language and literature',\n",
    " 3: 'Music',\n",
    " 4: 'Social sciences and society',\n",
    " 5: 'Sports and recreation',\n",
    " 6: 'Natural sciences',\n",
    " 7: 'Art and architecture',\n",
    " 8: 'History',\n",
    " 9: 'Warfare',\n",
    " 10: 'Engineering and technology',\n",
    " 11: 'Philosophy and religion',\n",
    " 12: 'Agriculture, food and drink',\n",
    " 13: 'Geography and places',\n",
    " 14: 'Mathematics',\n",
    " 15: 'Media and drama'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(11747)\n",
    "LOWER = False\n",
    "LEARNING_RATE = 3e-4\n",
    "N_CLASS = len(int2Label.keys())\n",
    "LOG_FILE = \"ConvNetClassificationTesting.txt\"\n",
    "VERBOSE_LOG_FILE = \"VerboseConvNetClassificationTesting.txt\"\n",
    "STEP_SIZE = 5\n",
    "GAMMA = 1.0\n",
    "NUMBER_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(LOG_FILE,\"w+\")\n",
    "v = open(VERBOSE_LOG_FILE, \"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "TEXT = Field(sequential=True, tokenize=tokenizer, lower=LOWER, batch_first=True)\n",
    "\n",
    "LABEL = Field(sequential=False, use_vocab=False, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = TabularDataset.splits(\".\", \n",
    "                                            train = \"topicclass_train.csv\", \n",
    "                                            validation = \"topicclass_valid_fixed.csv\", \n",
    "                                            test = \"topicclass_test.csv\", \n",
    "                                            format = \"csv\", \n",
    "                                            fields = [('label', LABEL), ('text', TEXT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train, val, test, vectors = \"fasttext.en.300d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"device is: {}\".format(device))\n",
    "f.write(\"device is: {}\\n\".format(device))\n",
    "v.write(\"device is: {}\\n\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = Iterator.splits(\n",
    "                                    (train, val), \n",
    "                                    batch_sizes = (32, 64), \n",
    "                                    shuffle = True, \n",
    "                                    sort_key = lambda x: len(x.text), \n",
    "                                    device = device, \n",
    "                                    )\n",
    "\n",
    "test_loader = Iterator(test, batch_size=64, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train': train_loader, 'val': val_loader}\n",
    "dataset_sizes = {'train': len(train_loader), 'val': len(val_loader)}\n",
    "\n",
    "Metric = namedtuple('Metric', ['loss', 'train_error', 'val_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvClassifier(nn.Module): \n",
    "    def __init__(self, vocab, n_class, channels_first = 64, channels_second = 64, kernel_first = 2, kernel_second = 2): \n",
    "        super().__init__()\n",
    "        self.vocab_size, self.embedding_size = vocab.vectors.shape\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_size, sparse = False)\n",
    "        self.embedding.weight.data.copy_(vocab.vectors)\n",
    "        \n",
    "        self.embedding_delta = nn.Embedding(self.vocab_size, self.embedding_size, sparse = False)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=self.embedding_size, out_channels=channels_first, dilation = 1, kernel_size = kernel_first, padding = kernel_first - 1)\n",
    "        self.bn1 = nn.BatchNorm1d(channels_first)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(in_channels=channels_first, out_channels=channels_second, dilation = 1, kernel_size = kernel_second, padding = kernel_second - 1)\n",
    "        self.bn2 = nn.BatchNorm1d(channels_second)\n",
    "    \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc = nn.Linear(channels_second, n_class)\n",
    "        \n",
    "    def forward(self, texts): \n",
    "        with torch.no_grad(): \n",
    "            static_embeddings = self.embedding(texts)\n",
    "        embeddings = static_embeddings + self.embedding_delta(texts)\n",
    "        conv1_out = self.conv1(embeddings.transpose(1,2))\n",
    "        conv1_out = self.bn1(conv1_out)\n",
    "        conv1_out = self.relu(conv1_out)\n",
    "        \n",
    "        conv2_out = self.conv2(conv1_out)\n",
    "        conv2_out = self.bn2(conv2_out)\n",
    "        conv2_out = self.relu(conv2_out) \n",
    "        \n",
    "        if conv1_out.shape == conv2_out.shape: \n",
    "            conv2_out += conv1_out\n",
    "        \n",
    "        pool = nn.MaxPool1d(kernel_size = conv2_out.shape[2])\n",
    "#         print(f\"conv2 shape is {conv2_out.shape}\")\n",
    "        \n",
    "        pooled_out = pool(conv2_out).squeeze(2)\n",
    "        \n",
    "#         print(f\"pooled out shape is {pooled_out.shape}\")\n",
    "        \n",
    "        out = self.fc(pooled_out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "\n",
    "    since = time.time()\n",
    "    \n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        f.write('Epoch {}/{}\\n'.format(epoch+1, num_epochs))\n",
    "        v.write('Epoch {}/{}\\n'.format(epoch+1, num_epochs))\n",
    "        f.write('-' *10)\n",
    "        v.write('-' * 10)\n",
    "\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            f.write(\"\\nstarting epoch {} for {} phase\\n\".format(epoch+1, phase))\n",
    "            v.write(\"\\nstarting epoch {} for {} phase\\n\".format(epoch+1, phase))\n",
    "            print(\"starting epoch {} for {} phase\".format(epoch+1, phase))\n",
    "\n",
    "            for i, data in enumerate(tqdm_notebook(dataloaders[phase])):\n",
    "                #pdb.set_trace()\n",
    "                inputs = data.text.to(device)\n",
    "                labels = data.label.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                if ((i%300) == 0):\n",
    "                    #print(\"inside\")\n",
    "                    v.write(\"inputs size: {}\\n\".format(inputs.size(0)))\n",
    "                    v.write(\"epoch {}, batch {},  loss : {}\\n\".format(epoch+1, i, loss.item()))\n",
    "                    v.write(\"percent correct: {}\\n\".format((torch.sum(preds == labels.data)/inputs.size(0))))\n",
    "            \n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            if phase == 'train':\n",
    "\n",
    "                train_loss = epoch_loss\n",
    "                train_error = 1 - epoch_acc\n",
    "                scheduler.step()\n",
    "\n",
    "            elif phase == 'val': \n",
    "\n",
    "                val_error = 1 - epoch_acc\n",
    "                metrics.append(Metric(loss=train_loss, train_error=train_error,val_error=val_error))\n",
    "            \n",
    "            f.write('{} Loss: {:.4f} Acc: {:.4f}\\n'.format(phase, epoch_loss, epoch_acc))\n",
    "            v.write('{} Loss: {:.4f} Acc: {:.4f}\\n'.format(phase, epoch_loss, epoch_acc))\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                PATH = 'MobileNetModel_' + str(epoch+2) + '.pt'\n",
    "                torch.save(model, PATH)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    f.write('Training complete in {:.0f}m {:.0f}s\\n'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    v.write('Training complete in {:.0f}m {:.0f}s\\n'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    f.write('Best val Acc: {:4f}'.format(best_acc))\n",
    "    v.write('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvClassifier(TEXT.vocab, N_CLASS, channels_first = 64, channels_second = 64, kernel_first = 2, kernel_second = 2)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n",
      "starting epoch 1 for train phase\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889b99dee6a94b659578a3da509bc032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7935), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-6e347d4ba1a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUMBER_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-176-bc7f0669ad1f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     47\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=NUMBER_EPOCHS)\n",
    "\n",
    "f.close()\n",
    "v.close()\n",
    "torch.save(model_ft, \"bestMobile_v2_NetModel.pt\")\n",
    "\n",
    "def training_plot(metrics):\n",
    "    plt.figure(1)\n",
    "    plt.plot([m.val_error for m in metrics], 'b')\n",
    "    plt.plot([m.train_error for m in metrics], 'r')\n",
    "    plt.title('Val Error (blue) Train Error (red)')\n",
    "    plt.savefig('Mobile_v2_NetPlot.png')\n",
    "\n",
    "training_plot(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
